{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb Cell 1\u001b[0m in \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb#W0sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     collection\u001b[39m.\u001b[39minsert_many(data_json)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb#W0sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     \u001b[39m# Wait for 5 seconds before fetching new data\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb#W0sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m2\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb#W0sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mExecution stopped by user\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "import time\n",
    "from kafka import KafkaProducer\n",
    "import json\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient(\"mongodb://localhost:27017\")\n",
    "db = client[\"DE_new\"]  # Replace \"your_database_name\" with your desired database name\n",
    "collection = db[\"col_1\"]  # Replace \"your_collection_name\" with your desired collection name\n",
    "\n",
    "# Kafka configuration\n",
    "kafka_bootstrap_servers = \"localhost:9092\"\n",
    "kafka_topic = \"Topic_1_Trade_Data\"  # Replace \"your_topic_name\" with your desired Kafka topic name\n",
    "\n",
    "# Create Kafka producer\n",
    "kafka_producer = KafkaProducer(bootstrap_servers=kafka_bootstrap_servers,\n",
    "                                    api_version=(0,11,5),\n",
    "                                    value_serializer=lambda v: json.dumps(v).encode('utf-8'))\n",
    "# Main loop to continuously update the database\n",
    "while True:\n",
    "    # Fetch data using yfinance\n",
    "    ticker = \"UBER\"  # Replace with your desired ticker symbol\n",
    "    data = yf.download(ticker, period=\"1d\", interval=\"1m\")\n",
    "\n",
    "    # Convert data to a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Convert DataFrame to JSON format\n",
    "    data_json = df.to_dict(orient=\"records\")\n",
    "\n",
    "    # Send data to Kafka topic\n",
    "    kafka_producer.send(kafka_topic, value=data_json)\n",
    "\n",
    "    # Insert data into MongoDB\n",
    "    collection.insert_many(data_json)\n",
    "    \n",
    "    # Wait for 5 seconds before fetching new data\n",
    "    time.sleep(2)\n",
    "\n",
    "print(\"Execution stopped by user\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "DefaultCredentialsError",
     "evalue": "Could not automatically determine credentials. Please set GOOGLE_APPLICATION_CREDENTIALS or explicitly create credentials and re-run the application. For more information, please see https://cloud.google.com/docs/authentication/getting-started",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDefaultCredentialsError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb Cell 2\u001b[0m in \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb#W1sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# GCS configuration\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb#W1sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m gcs_bucket_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtrading_data_new\u001b[39m\u001b[39m\"\u001b[39m  \u001b[39m# Replace with your GCS bucket name\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb#W1sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m gcs_client \u001b[39m=\u001b[39m storage\u001b[39m.\u001b[39;49mClient()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb#W1sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# Kafka configuration\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb#W1sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m kafka_bootstrap_servers \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlocalhost:9092\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SRH_Python/lib/python3.9/site-packages/google/cloud/storage/client.py:161\u001b[0m, in \u001b[0;36mClient.__init__\u001b[0;34m(self, project, credentials, _http, client_info, client_options)\u001b[0m\n\u001b[1;32m    158\u001b[0m         no_project \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    159\u001b[0m         project \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m<none>\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 161\u001b[0m \u001b[39msuper\u001b[39;49m(Client, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m    162\u001b[0m     project\u001b[39m=\u001b[39;49mproject,\n\u001b[1;32m    163\u001b[0m     credentials\u001b[39m=\u001b[39;49mcredentials,\n\u001b[1;32m    164\u001b[0m     client_options\u001b[39m=\u001b[39;49mclient_options,\n\u001b[1;32m    165\u001b[0m     _http\u001b[39m=\u001b[39;49m_http,\n\u001b[1;32m    166\u001b[0m )\n\u001b[1;32m    168\u001b[0m \u001b[39mif\u001b[39;00m no_project:\n\u001b[1;32m    169\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproject \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SRH_Python/lib/python3.9/site-packages/google/cloud/client/__init__.py:320\u001b[0m, in \u001b[0;36mClientWithProject.__init__\u001b[0;34m(self, project, credentials, client_options, _http)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, project\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, credentials\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, client_options\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, _http\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 320\u001b[0m     _ClientProjectMixin\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39mself\u001b[39;49m, project\u001b[39m=\u001b[39;49mproject, credentials\u001b[39m=\u001b[39;49mcredentials)\n\u001b[1;32m    321\u001b[0m     Client\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\n\u001b[1;32m    322\u001b[0m         \u001b[39mself\u001b[39m, credentials\u001b[39m=\u001b[39mcredentials, client_options\u001b[39m=\u001b[39mclient_options, _http\u001b[39m=\u001b[39m_http\n\u001b[1;32m    323\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SRH_Python/lib/python3.9/site-packages/google/cloud/client/__init__.py:268\u001b[0m, in \u001b[0;36m_ClientProjectMixin.__init__\u001b[0;34m(self, project, credentials)\u001b[0m\n\u001b[1;32m    265\u001b[0m     project \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(credentials, \u001b[39m\"\u001b[39m\u001b[39mproject_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    267\u001b[0m \u001b[39mif\u001b[39;00m project \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 268\u001b[0m     project \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_determine_default(project)\n\u001b[1;32m    270\u001b[0m \u001b[39mif\u001b[39;00m project \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    271\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    272\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mProject was not passed and could not be \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    273\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdetermined from the environment.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SRH_Python/lib/python3.9/site-packages/google/cloud/client/__init__.py:287\u001b[0m, in \u001b[0;36m_ClientProjectMixin._determine_default\u001b[0;34m(project)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    285\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_determine_default\u001b[39m(project):\n\u001b[1;32m    286\u001b[0m     \u001b[39m\"\"\"Helper:  use default project detection.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 287\u001b[0m     \u001b[39mreturn\u001b[39;00m _determine_default_project(project)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SRH_Python/lib/python3.9/site-packages/google/cloud/_helpers/__init__.py:152\u001b[0m, in \u001b[0;36m_determine_default_project\u001b[0;34m(project)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39m\"\"\"Determine default project ID explicitly or implicitly as fall-back.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \n\u001b[1;32m    142\u001b[0m \u001b[39mSee :func:`google.auth.default` for details on how the default project\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[39m:returns: Default project if it can be determined.\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[39mif\u001b[39;00m project \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 152\u001b[0m     _, project \u001b[39m=\u001b[39m google\u001b[39m.\u001b[39;49mauth\u001b[39m.\u001b[39;49mdefault()\n\u001b[1;32m    153\u001b[0m \u001b[39mreturn\u001b[39;00m project\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SRH_Python/lib/python3.9/site-packages/google/auth/_default.py:575\u001b[0m, in \u001b[0;36mdefault\u001b[0;34m(scopes, request, quota_project_id, default_scopes)\u001b[0m\n\u001b[1;32m    567\u001b[0m             _LOGGER\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    568\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mNo project ID could be determined. Consider running \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m`gcloud config set project` or setting the \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39menvironment variable\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    571\u001b[0m                 environment_vars\u001b[39m.\u001b[39mPROJECT,\n\u001b[1;32m    572\u001b[0m             )\n\u001b[1;32m    573\u001b[0m         \u001b[39mreturn\u001b[39;00m credentials, effective_project_id\n\u001b[0;32m--> 575\u001b[0m \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mDefaultCredentialsError(_HELP_MESSAGE)\n",
      "\u001b[0;31mDefaultCredentialsError\u001b[0m: Could not automatically determine credentials. Please set GOOGLE_APPLICATION_CREDENTIALS or explicitly create credentials and re-run the application. For more information, please see https://cloud.google.com/docs/authentication/getting-started"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from google.cloud import storage\n",
    "import time\n",
    "from kafka import KafkaProducer\n",
    "import json\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient(\"mongodb://localhost:27017\")\n",
    "db = client[\"DE_new\"]\n",
    "collection = db[\"col_1\"]\n",
    "\n",
    "# GCS configuration\n",
    "gcs_bucket_name = \"trading_data_new\"  # Replace with your GCS bucket name\n",
    "gcs_client = storage.Client()\n",
    "\n",
    "# Kafka configuration\n",
    "kafka_bootstrap_servers = \"localhost:9092\"\n",
    "kafka_topic = \"Topic_1_Trade_Data\"\n",
    "\n",
    "# Create Kafka producer\n",
    "kafka_producer = KafkaProducer(\n",
    "    bootstrap_servers=kafka_bootstrap_servers,\n",
    "    api_version=(0, 11, 5),\n",
    "    value_serializer=lambda v: json.dumps(v).encode('utf-8')\n",
    ")\n",
    "\n",
    "# Main loop to continuously update the database and upload to GCS\n",
    "while True:\n",
    "    # Fetch data using yfinance\n",
    "    ticker = \"UBER\"  # Replace with your desired ticker symbol\n",
    "    data = yf.download(ticker, period=\"1d\", interval=\"1m\")\n",
    "    df = pd.DataFrame(data)\n",
    "    data_json = df.to_dict(orient=\"records\")\n",
    "\n",
    "    # Send data to Kafka topic\n",
    "    kafka_producer.send(kafka_topic, value=data_json)\n",
    "\n",
    "    # Insert data into MongoDB\n",
    "    collection.insert_many(data_json)\n",
    "\n",
    "    # Upload data to GCS\n",
    "    bucket = gcs_client.bucket(gcs_bucket_name)\n",
    "    blob = bucket.blob(\"data.json\")\n",
    "    blob.upload_from_string(json.dumps(data_json), content_type=\"application/json\")\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "print(\"Execution stopped by user\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type ObjectId is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb Cell 3\u001b[0m in \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb#W2sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     bucket \u001b[39m=\u001b[39m gcs_client\u001b[39m.\u001b[39mbucket(gcs_bucket_name)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb#W2sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     blob \u001b[39m=\u001b[39m bucket\u001b[39m.\u001b[39mblob(\u001b[39m\"\u001b[39m\u001b[39mdata.json\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb#W2sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m     blob\u001b[39m.\u001b[39mupload_from_string(json\u001b[39m.\u001b[39;49mdumps(data_json), content_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapplication/json\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb#W2sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m2\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb#W2sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mExecution stopped by user\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SRH_Python/lib/python3.9/json/__init__.py:231\u001b[0m, in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[39m# cached encoder\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mnot\u001b[39;00m skipkeys \u001b[39mand\u001b[39;00m ensure_ascii \u001b[39mand\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     check_circular \u001b[39mand\u001b[39;00m allow_nan \u001b[39mand\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m indent \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m separators \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     default \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m sort_keys \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[0;32m--> 231\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_encoder\u001b[39m.\u001b[39;49mencode(obj)\n\u001b[1;32m    232\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m JSONEncoder\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SRH_Python/lib/python3.9/json/encoder.py:199\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[39mreturn\u001b[39;00m encode_basestring(o)\n\u001b[1;32m    196\u001b[0m \u001b[39m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[39m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterencode(o, _one_shot\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    200\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(chunks, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[1;32m    201\u001b[0m     chunks \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(chunks)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SRH_Python/lib/python3.9/json/encoder.py:257\u001b[0m, in \u001b[0;36mJSONEncoder.iterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     _iterencode \u001b[39m=\u001b[39m _make_iterencode(\n\u001b[1;32m    254\u001b[0m         markers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault, _encoder, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindent, floatstr,\n\u001b[1;32m    255\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkey_separator, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem_separator, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msort_keys,\n\u001b[1;32m    256\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mskipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0m \u001b[39mreturn\u001b[39;00m _iterencode(o, \u001b[39m0\u001b[39;49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SRH_Python/lib/python3.9/site-packages/frozendict/__init__.py:32\u001b[0m, in \u001b[0;36m_getFrozendictJsonEncoder.<locals>.FrozendictJsonEncoder.default\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, frozendict):\n\u001b[1;32m     28\u001b[0m     \u001b[39m# TODO create a C serializer\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mdict\u001b[39m(obj)\n\u001b[0;32m---> 32\u001b[0m \u001b[39mreturn\u001b[39;00m BaseJsonEncoder\u001b[39m.\u001b[39;49mdefault(\u001b[39mself\u001b[39;49m, obj)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SRH_Python/lib/python3.9/json/encoder.py:179\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault\u001b[39m(\u001b[39mself\u001b[39m, o):\n\u001b[1;32m    161\u001b[0m     \u001b[39m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[39m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m \n\u001b[1;32m    178\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mObject of type \u001b[39m\u001b[39m{\u001b[39;00mo\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    180\u001b[0m                     \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mis not JSON serializable\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type ObjectId is not JSON serializable"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from google.cloud import storage\n",
    "import os\n",
    "import time\n",
    "from kafka import KafkaProducer\n",
    "import json\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient(\"mongodb://localhost:27017\")\n",
    "db = client[\"DE_new\"]\n",
    "collection = db[\"col_1\"]\n",
    "\n",
    "# GCS configuration\n",
    "gcs_bucket_name = \"trading_data_new\"  # Replace with your GCS bucket name\n",
    "# Specify the path to the service account key file\n",
    "key_path = \"/Users/Rohaan/Desktop/DE/Data_Engineering_Project/key.json\"\n",
    "# Create credentials\n",
    "credentials = service_account.Credentials.from_service_account_file(key_path)\n",
    "# Use credentials for authentication\n",
    "gcs_client = storage.Client(credentials=credentials)\n",
    "\n",
    "\n",
    "# Set GCP credentials environment variable\n",
    "#os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/Users/Rohaan/Desktop/DE/Data_Engineering_Project/key.json\"\n",
    "\n",
    "# Kafka configuration\n",
    "kafka_bootstrap_servers = \"localhost:9092\"\n",
    "kafka_topic = \"Topic_1_Trade_Data\"\n",
    "\n",
    "# Create Kafka producer\n",
    "kafka_producer = KafkaProducer(\n",
    "    bootstrap_servers=kafka_bootstrap_servers,\n",
    "    api_version=(0, 11, 5),\n",
    "    value_serializer=lambda v: json.dumps(v).encode('utf-8')\n",
    ")\n",
    "\n",
    "# Main loop to continuously update the database and upload to GCS\n",
    "while True:\n",
    "    # Fetch data using yfinance\n",
    "    ticker = \"UBER\"  # Replace with your desired ticker symbol\n",
    "    data = yf.download(ticker, period=\"1d\", interval=\"1m\")\n",
    "    df = pd.DataFrame(data)\n",
    "    data_json = df.to_dict(orient=\"records\")\n",
    "\n",
    "    # Send data to Kafka topic\n",
    "    kafka_producer.send(kafka_topic, value=data_json)\n",
    "\n",
    "    # Insert data into MongoDB\n",
    "    collection.insert_many(data_json)\n",
    "\n",
    "    # Upload data to GCS\n",
    "    bucket = gcs_client.bucket(gcs_bucket_name)\n",
    "    blob = bucket.blob(\"data.json\")\n",
    "    blob.upload_from_string(json.dumps(data_json), content_type=\"application/json\")\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "print(\"Execution stopped by user\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.oauth2 import service_account\n",
    "\n",
    "# Specify the path to the service account key file\n",
    "key_path = \"/Users/Rohaan/Desktop/DE/Data_Engineering_Project/key.json\"\n",
    "\n",
    "# Create credentials\n",
    "credentials = service_account.Credentials.from_service_account_file(key_path)\n",
    "\n",
    "# Use credentials for authentication\n",
    "gcs_client = storage.Client(credentials=credentials)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type ObjectId is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb Cell 5\u001b[0m in \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb#W4sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m     bucket \u001b[39m=\u001b[39m gcs_client\u001b[39m.\u001b[39mbucket(gcs_bucket_name)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb#W4sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m     blob \u001b[39m=\u001b[39m bucket\u001b[39m.\u001b[39mblob(\u001b[39m\"\u001b[39m\u001b[39mdata.json\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb#W4sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m     blob\u001b[39m.\u001b[39mupload_from_string(json\u001b[39m.\u001b[39;49mdumps(data_json), content_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapplication/json\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb#W4sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m2\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb#W4sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mExecution stopped by user\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SRH_Python/lib/python3.9/json/__init__.py:231\u001b[0m, in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[39m# cached encoder\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mnot\u001b[39;00m skipkeys \u001b[39mand\u001b[39;00m ensure_ascii \u001b[39mand\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     check_circular \u001b[39mand\u001b[39;00m allow_nan \u001b[39mand\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m indent \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m separators \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     default \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m sort_keys \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[0;32m--> 231\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_encoder\u001b[39m.\u001b[39;49mencode(obj)\n\u001b[1;32m    232\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m JSONEncoder\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SRH_Python/lib/python3.9/json/encoder.py:199\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[39mreturn\u001b[39;00m encode_basestring(o)\n\u001b[1;32m    196\u001b[0m \u001b[39m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[39m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterencode(o, _one_shot\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    200\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(chunks, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[1;32m    201\u001b[0m     chunks \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(chunks)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SRH_Python/lib/python3.9/json/encoder.py:257\u001b[0m, in \u001b[0;36mJSONEncoder.iterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     _iterencode \u001b[39m=\u001b[39m _make_iterencode(\n\u001b[1;32m    254\u001b[0m         markers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault, _encoder, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindent, floatstr,\n\u001b[1;32m    255\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkey_separator, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem_separator, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msort_keys,\n\u001b[1;32m    256\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mskipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0m \u001b[39mreturn\u001b[39;00m _iterencode(o, \u001b[39m0\u001b[39;49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SRH_Python/lib/python3.9/site-packages/frozendict/__init__.py:32\u001b[0m, in \u001b[0;36m_getFrozendictJsonEncoder.<locals>.FrozendictJsonEncoder.default\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, frozendict):\n\u001b[1;32m     28\u001b[0m     \u001b[39m# TODO create a C serializer\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mdict\u001b[39m(obj)\n\u001b[0;32m---> 32\u001b[0m \u001b[39mreturn\u001b[39;00m BaseJsonEncoder\u001b[39m.\u001b[39;49mdefault(\u001b[39mself\u001b[39;49m, obj)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SRH_Python/lib/python3.9/json/encoder.py:179\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault\u001b[39m(\u001b[39mself\u001b[39m, o):\n\u001b[1;32m    161\u001b[0m     \u001b[39m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[39m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m \n\u001b[1;32m    178\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mObject of type \u001b[39m\u001b[39m{\u001b[39;00mo\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    180\u001b[0m                     \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mis not JSON serializable\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type ObjectId is not JSON serializable"
     ]
    }
   ],
   "source": [
    "#t-1\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from google.cloud import storage\n",
    "import os\n",
    "import time\n",
    "from kafka import KafkaProducer\n",
    "import json\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient(\"mongodb://localhost:27017\")\n",
    "db = client[\"DE_new\"]\n",
    "collection = db[\"col_1\"]\n",
    "\n",
    "# GCS configuration\n",
    "gcs_bucket_name = \"trading_data_new\"  # Replace with your GCS bucket name\n",
    "# Specify the path to the service account key file\n",
    "key_path = \"/Users/Rohaan/Desktop/DE/Data_Engineering_Project/key.json\"\n",
    "# Create credentials\n",
    "credentials = service_account.Credentials.from_service_account_file(key_path)\n",
    "# Use credentials for authentication\n",
    "gcs_client = storage.Client(credentials=credentials)\n",
    "\n",
    "\n",
    "# Set GCP credentials environment variable\n",
    "# os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/Users/Rohaan/Desktop/DE/Data_Engineering_Project/key.json\"\n",
    "\n",
    "# Kafka configuration\n",
    "kafka_bootstrap_servers = \"localhost:9092\"\n",
    "kafka_topic = \"Topic_1_Trade_Data\"\n",
    "\n",
    "# Create Kafka producer\n",
    "kafka_producer = KafkaProducer(\n",
    "    bootstrap_servers=kafka_bootstrap_servers,\n",
    "    api_version=(0, 11, 5),\n",
    "    value_serializer=lambda v: json.dumps(v).encode('utf-8')\n",
    ")\n",
    "\n",
    "# Main loop to continuously update the database and upload to GCS\n",
    "while True:\n",
    "    # Fetch data using yfinance\n",
    "    ticker = \"UBER\"  # Replace with your desired ticker symbol\n",
    "    data = yf.download(ticker, period=\"1d\", interval=\"1m\")\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Convert DataFrame to JSON format\n",
    "    data_json = df.to_dict(orient=\"records\")\n",
    "\n",
    "    # Send data to Kafka topic\n",
    "    kafka_producer.send(kafka_topic, value=data_json)\n",
    "\n",
    "    # Insert data into MongoDB\n",
    "    collection.insert_many(data_json)\n",
    "\n",
    "    # Upload data to GCS\n",
    "    bucket = gcs_client.bucket(gcs_bucket_name)\n",
    "    blob = bucket.blob(\"data.json\")\n",
    "    blob.upload_from_string(json.dumps(data_json), content_type=\"application/json\")\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "print(\"Execution stopped by user\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb Cell 6\u001b[0m in \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb#W5sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m     bucket \u001b[39m=\u001b[39m gcs_client\u001b[39m.\u001b[39mbucket(gcs_bucket_name)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb#W5sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m     blob \u001b[39m=\u001b[39m bucket\u001b[39m.\u001b[39mblob(\u001b[39m\"\u001b[39m\u001b[39mdata.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb#W5sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m     blob\u001b[39m.\u001b[39;49mupload_from_string(csv_data, content_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtext/csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb#W5sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m2\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb#W5sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mExecution stopped by user\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SRH_Python/lib/python3.9/site-packages/google/cloud/storage/blob.py:2814\u001b[0m, in \u001b[0;36mBlob.upload_from_string\u001b[0;34m(self, data, content_type, num_retries, client, predefined_acl, if_generation_match, if_generation_not_match, if_metageneration_match, if_metageneration_not_match, timeout, checksum, retry)\u001b[0m\n\u001b[1;32m   2812\u001b[0m data \u001b[39m=\u001b[39m _to_bytes(data, encoding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   2813\u001b[0m string_buffer \u001b[39m=\u001b[39m BytesIO(data)\n\u001b[0;32m-> 2814\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupload_from_file(\n\u001b[1;32m   2815\u001b[0m     file_obj\u001b[39m=\u001b[39;49mstring_buffer,\n\u001b[1;32m   2816\u001b[0m     size\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(data),\n\u001b[1;32m   2817\u001b[0m     content_type\u001b[39m=\u001b[39;49mcontent_type,\n\u001b[1;32m   2818\u001b[0m     num_retries\u001b[39m=\u001b[39;49mnum_retries,\n\u001b[1;32m   2819\u001b[0m     client\u001b[39m=\u001b[39;49mclient,\n\u001b[1;32m   2820\u001b[0m     predefined_acl\u001b[39m=\u001b[39;49mpredefined_acl,\n\u001b[1;32m   2821\u001b[0m     if_generation_match\u001b[39m=\u001b[39;49mif_generation_match,\n\u001b[1;32m   2822\u001b[0m     if_generation_not_match\u001b[39m=\u001b[39;49mif_generation_not_match,\n\u001b[1;32m   2823\u001b[0m     if_metageneration_match\u001b[39m=\u001b[39;49mif_metageneration_match,\n\u001b[1;32m   2824\u001b[0m     if_metageneration_not_match\u001b[39m=\u001b[39;49mif_metageneration_not_match,\n\u001b[1;32m   2825\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m   2826\u001b[0m     checksum\u001b[39m=\u001b[39;49mchecksum,\n\u001b[1;32m   2827\u001b[0m     retry\u001b[39m=\u001b[39;49mretry,\n\u001b[1;32m   2828\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SRH_Python/lib/python3.9/site-packages/google/cloud/storage/blob.py:2539\u001b[0m, in \u001b[0;36mBlob.upload_from_file\u001b[0;34m(self, file_obj, rewind, size, content_type, num_retries, client, predefined_acl, if_generation_match, if_generation_not_match, if_metageneration_match, if_metageneration_not_match, timeout, checksum, retry)\u001b[0m\n\u001b[1;32m   2536\u001b[0m predefined_acl \u001b[39m=\u001b[39m ACL\u001b[39m.\u001b[39mvalidate_predefined(predefined_acl)\n\u001b[1;32m   2538\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 2539\u001b[0m     created_json \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_upload(\n\u001b[1;32m   2540\u001b[0m         client,\n\u001b[1;32m   2541\u001b[0m         file_obj,\n\u001b[1;32m   2542\u001b[0m         content_type,\n\u001b[1;32m   2543\u001b[0m         size,\n\u001b[1;32m   2544\u001b[0m         num_retries,\n\u001b[1;32m   2545\u001b[0m         predefined_acl,\n\u001b[1;32m   2546\u001b[0m         if_generation_match,\n\u001b[1;32m   2547\u001b[0m         if_generation_not_match,\n\u001b[1;32m   2548\u001b[0m         if_metageneration_match,\n\u001b[1;32m   2549\u001b[0m         if_metageneration_not_match,\n\u001b[1;32m   2550\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m   2551\u001b[0m         checksum\u001b[39m=\u001b[39;49mchecksum,\n\u001b[1;32m   2552\u001b[0m         retry\u001b[39m=\u001b[39;49mretry,\n\u001b[1;32m   2553\u001b[0m     )\n\u001b[1;32m   2554\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_properties(created_json)\n\u001b[1;32m   2555\u001b[0m \u001b[39mexcept\u001b[39;00m resumable_media\u001b[39m.\u001b[39mInvalidResponse \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SRH_Python/lib/python3.9/site-packages/google/cloud/storage/blob.py:2354\u001b[0m, in \u001b[0;36mBlob._do_upload\u001b[0;34m(self, client, stream, content_type, size, num_retries, predefined_acl, if_generation_match, if_generation_not_match, if_metageneration_match, if_metageneration_not_match, timeout, checksum, retry)\u001b[0m\n\u001b[1;32m   2351\u001b[0m     retry \u001b[39m=\u001b[39m retry\u001b[39m.\u001b[39mget_retry_policy_if_conditions_met(query_params\u001b[39m=\u001b[39mquery_params)\n\u001b[1;32m   2353\u001b[0m \u001b[39mif\u001b[39;00m size \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m size \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m _MAX_MULTIPART_SIZE:\n\u001b[0;32m-> 2354\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_multipart_upload(\n\u001b[1;32m   2355\u001b[0m         client,\n\u001b[1;32m   2356\u001b[0m         stream,\n\u001b[1;32m   2357\u001b[0m         content_type,\n\u001b[1;32m   2358\u001b[0m         size,\n\u001b[1;32m   2359\u001b[0m         num_retries,\n\u001b[1;32m   2360\u001b[0m         predefined_acl,\n\u001b[1;32m   2361\u001b[0m         if_generation_match,\n\u001b[1;32m   2362\u001b[0m         if_generation_not_match,\n\u001b[1;32m   2363\u001b[0m         if_metageneration_match,\n\u001b[1;32m   2364\u001b[0m         if_metageneration_not_match,\n\u001b[1;32m   2365\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m   2366\u001b[0m         checksum\u001b[39m=\u001b[39;49mchecksum,\n\u001b[1;32m   2367\u001b[0m         retry\u001b[39m=\u001b[39;49mretry,\n\u001b[1;32m   2368\u001b[0m     )\n\u001b[1;32m   2369\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2370\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_resumable_upload(\n\u001b[1;32m   2371\u001b[0m         client,\n\u001b[1;32m   2372\u001b[0m         stream,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2383\u001b[0m         retry\u001b[39m=\u001b[39mretry,\n\u001b[1;32m   2384\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SRH_Python/lib/python3.9/site-packages/google/cloud/storage/blob.py:1889\u001b[0m, in \u001b[0;36mBlob._do_multipart_upload\u001b[0;34m(self, client, stream, content_type, size, num_retries, predefined_acl, if_generation_match, if_generation_not_match, if_metageneration_match, if_metageneration_not_match, timeout, checksum, retry)\u001b[0m\n\u001b[1;32m   1883\u001b[0m upload \u001b[39m=\u001b[39m MultipartUpload(upload_url, headers\u001b[39m=\u001b[39mheaders, checksum\u001b[39m=\u001b[39mchecksum)\n\u001b[1;32m   1885\u001b[0m upload\u001b[39m.\u001b[39m_retry_strategy \u001b[39m=\u001b[39m _api_core_retry_to_resumable_media_retry(\n\u001b[1;32m   1886\u001b[0m     retry, num_retries\n\u001b[1;32m   1887\u001b[0m )\n\u001b[0;32m-> 1889\u001b[0m response \u001b[39m=\u001b[39m upload\u001b[39m.\u001b[39;49mtransmit(\n\u001b[1;32m   1890\u001b[0m     transport, data, object_metadata, content_type, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m   1891\u001b[0m )\n\u001b[1;32m   1893\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SRH_Python/lib/python3.9/site-packages/google/resumable_media/requests/upload.py:153\u001b[0m, in \u001b[0;36mMultipartUpload.transmit\u001b[0;34m(self, transport, data, metadata, content_type, timeout)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_response(result)\n\u001b[1;32m    151\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m--> 153\u001b[0m \u001b[39mreturn\u001b[39;00m _request_helpers\u001b[39m.\u001b[39;49mwait_and_retry(\n\u001b[1;32m    154\u001b[0m     retriable_request, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_status_code, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_retry_strategy\n\u001b[1;32m    155\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SRH_Python/lib/python3.9/site-packages/google/resumable_media/requests/_request_helpers.py:148\u001b[0m, in \u001b[0;36mwait_and_retry\u001b[0;34m(func, get_status_code, retry_strategy)\u001b[0m\n\u001b[1;32m    146\u001b[0m error \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 148\u001b[0m     response \u001b[39m=\u001b[39m func()\n\u001b[1;32m    149\u001b[0m \u001b[39mexcept\u001b[39;00m _CONNECTION_ERROR_CLASSES \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    150\u001b[0m     error \u001b[39m=\u001b[39m e  \u001b[39m# Fall through to retry, if there are retries left.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SRH_Python/lib/python3.9/site-packages/google/resumable_media/requests/upload.py:145\u001b[0m, in \u001b[0;36mMultipartUpload.transmit.<locals>.retriable_request\u001b[0;34m()\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mretriable_request\u001b[39m():\n\u001b[0;32m--> 145\u001b[0m     result \u001b[39m=\u001b[39m transport\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    146\u001b[0m         method, url, data\u001b[39m=\u001b[39;49mpayload, headers\u001b[39m=\u001b[39;49mheaders, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m    147\u001b[0m     )\n\u001b[1;32m    149\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_response(result)\n\u001b[1;32m    151\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SRH_Python/lib/python3.9/site-packages/google/auth/transport/requests.py:480\u001b[0m, in \u001b[0;36mAuthorizedSession.request\u001b[0;34m(self, method, url, data, headers, max_allowed_time, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    477\u001b[0m remaining_time \u001b[39m=\u001b[39m guard\u001b[39m.\u001b[39mremaining_timeout\n\u001b[1;32m    479\u001b[0m \u001b[39mwith\u001b[39;00m TimeoutGuard(remaining_time) \u001b[39mas\u001b[39;00m guard:\n\u001b[0;32m--> 480\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(AuthorizedSession, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    481\u001b[0m         method,\n\u001b[1;32m    482\u001b[0m         url,\n\u001b[1;32m    483\u001b[0m         data\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m    484\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest_headers,\n\u001b[1;32m    485\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    486\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    487\u001b[0m     )\n\u001b[1;32m    488\u001b[0m remaining_time \u001b[39m=\u001b[39m guard\u001b[39m.\u001b[39mremaining_timeout\n\u001b[1;32m    490\u001b[0m \u001b[39m# If the response indicated that the credentials needed to be\u001b[39;00m\n\u001b[1;32m    491\u001b[0m \u001b[39m# refreshed, then refresh the credentials and re-attempt the\u001b[39;00m\n\u001b[1;32m    492\u001b[0m \u001b[39m# request.\u001b[39;00m\n\u001b[1;32m    493\u001b[0m \u001b[39m# A stored token may expire between the time it is retrieved and\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \u001b[39m# the time the request is made, so we may need to try twice.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SRH_Python/lib/python3.9/site-packages/requests/sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    582\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    583\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    584\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    585\u001b[0m }\n\u001b[1;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SRH_Python/lib/python3.9/site-packages/requests/sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    698\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    700\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    703\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    704\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SRH_Python/lib/python3.9/site-packages/requests/adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    488\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 489\u001b[0m         resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    490\u001b[0m             method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    491\u001b[0m             url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    492\u001b[0m             body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    493\u001b[0m             headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    494\u001b[0m             redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m             assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    496\u001b[0m             preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    497\u001b[0m             decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    498\u001b[0m             retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    499\u001b[0m             timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    500\u001b[0m         )\n\u001b[1;32m    502\u001b[0m     \u001b[39m# Send the request.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(conn, \u001b[39m\"\u001b[39m\u001b[39mproxy_pool\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SRH_Python/lib/python3.9/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    704\u001b[0m     conn,\n\u001b[1;32m    705\u001b[0m     method,\n\u001b[1;32m    706\u001b[0m     url,\n\u001b[1;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    711\u001b[0m )\n\u001b[1;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SRH_Python/lib/python3.9/site-packages/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    444\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[1;32m    445\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    451\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SRH_Python/lib/python3.9/site-packages/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[1;32m    443\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    445\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SRH_Python/lib/python3.9/http/client.py:1377\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1377\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1378\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1379\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SRH_Python/lib/python3.9/http/client.py:320\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    321\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    322\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SRH_Python/lib/python3.9/http/client.py:281\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 281\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    282\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    283\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SRH_Python/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    705\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SRH_Python/lib/python3.9/ssl.py:1242\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1238\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1239\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1240\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1241\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1242\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1243\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1244\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SRH_Python/lib/python3.9/ssl.py:1100\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1099\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1100\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1101\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1102\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#running code\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from google.cloud import storage\n",
    "import os\n",
    "import time\n",
    "from kafka import KafkaProducer\n",
    "import json\n",
    "from bson import ObjectId\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient(\"mongodb://localhost:27017\")\n",
    "db = client[\"DE_new\"]\n",
    "collection = db[\"col_1\"]\n",
    "\n",
    "# GCS configuration\n",
    "gcs_bucket_name = \"trading_data_new\"  # Replace with your GCS bucket name\n",
    "# Specify the path to the service account key file\n",
    "key_path = \"/Users/Rohaan/Desktop/DE/Data_Engineering_Project/key.json\"\n",
    "# Create credentials\n",
    "credentials = service_account.Credentials.from_service_account_file(key_path)\n",
    "# Use credentials for authentication\n",
    "gcs_client = storage.Client(credentials=credentials)\n",
    "\n",
    "\n",
    "# Set GCP credentials environment variable\n",
    "# os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/Users/Rohaan/Desktop/DE/Data_Engineering_Project/key.json\"\n",
    "\n",
    "# Kafka configuration\n",
    "kafka_bootstrap_servers = \"localhost:9092\"\n",
    "kafka_topic = \"Topic_1_Trade_Data\"\n",
    "\n",
    "# Create Kafka producer\n",
    "kafka_producer = KafkaProducer(\n",
    "    bootstrap_servers=kafka_bootstrap_servers,\n",
    "    api_version=(0, 11, 5),\n",
    "    value_serializer=lambda v: json.dumps(v, default=str).encode('utf-8')\n",
    ")\n",
    "\n",
    "# Main loop to continuously update the database and upload to GCS\n",
    "while True:\n",
    "    # Fetch data using yfinance\n",
    "    ticker = \"UBER\"  # Replace with your desired ticker symbol\n",
    "    data = yf.download(ticker, period=\"1d\", interval=\"1m\")\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Convert DataFrame to CSV format\n",
    "    csv_data = df.to_csv(index=False)\n",
    "\n",
    "    # Send data to Kafka topic\n",
    "    kafka_producer.send(kafka_topic, value=csv_data.encode('utf-8'))\n",
    "\n",
    "    # Insert data into MongoDB\n",
    "    collection.insert_many(df.to_dict(orient=\"records\"))\n",
    "\n",
    "    # Upload data to GCS\n",
    "    bucket = gcs_client.bucket(gcs_bucket_name)\n",
    "    blob = bucket.blob(\"data.csv\")\n",
    "    blob.upload_from_string(csv_data, content_type=\"text/csv\")\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "print(\"Execution stopped by user\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb Cell 7\u001b[0m in \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb#W6sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb#W6sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     \u001b[39m# Fetch data using yfinance\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb#W6sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     ticker \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mUBER\u001b[39m\u001b[39m\"\u001b[39m  \u001b[39m# Replace with your desired ticker symbol\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb#W6sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     data \u001b[39m=\u001b[39m yf\u001b[39m.\u001b[39;49mdownload(ticker, period\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m1d\u001b[39;49m\u001b[39m\"\u001b[39;49m, interval\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m1m\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb#W6sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(data)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb#W6sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     \u001b[39m# Generate a unique name for the DataFrame\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SRH_Python/lib/python3.9/site-packages/yfinance/multi.py:144\u001b[0m, in \u001b[0;36mdownload\u001b[0;34m(tickers, start, end, actions, threads, ignore_tz, group_by, auto_adjust, back_adjust, repair, keepna, progress, period, show_errors, interval, prepost, proxy, rounding, timeout, session)\u001b[0m\n\u001b[1;32m    137\u001b[0m         _download_one_threaded(ticker, period\u001b[39m=\u001b[39mperiod, interval\u001b[39m=\u001b[39minterval,\n\u001b[1;32m    138\u001b[0m                                start\u001b[39m=\u001b[39mstart, end\u001b[39m=\u001b[39mend, prepost\u001b[39m=\u001b[39mprepost,\n\u001b[1;32m    139\u001b[0m                                actions\u001b[39m=\u001b[39mactions, auto_adjust\u001b[39m=\u001b[39mauto_adjust,\n\u001b[1;32m    140\u001b[0m                                back_adjust\u001b[39m=\u001b[39mback_adjust, repair\u001b[39m=\u001b[39mrepair, keepna\u001b[39m=\u001b[39mkeepna,\n\u001b[1;32m    141\u001b[0m                                progress\u001b[39m=\u001b[39m(progress \u001b[39mand\u001b[39;00m i \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m), proxy\u001b[39m=\u001b[39mproxy,\n\u001b[1;32m    142\u001b[0m                                rounding\u001b[39m=\u001b[39mrounding, timeout\u001b[39m=\u001b[39mtimeout, session\u001b[39m=\u001b[39msession)\n\u001b[1;32m    143\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mlen\u001b[39m(shared\u001b[39m.\u001b[39m_DFS) \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(tickers):\n\u001b[0;32m--> 144\u001b[0m         _time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n\u001b[1;32m    145\u001b[0m \u001b[39m# download synchronously\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    147\u001b[0m     \u001b[39mfor\u001b[39;00m i, ticker \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tickers):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from google.cloud import storage\n",
    "import os\n",
    "import time\n",
    "from kafka import KafkaProducer\n",
    "import json\n",
    "from datetime import datetime\n",
    "from bson import ObjectId\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient(\"mongodb://localhost:27017\")\n",
    "db = client[\"DE_new\"]\n",
    "collection = db[\"col_1\"]\n",
    "\n",
    "# GCS configuration\n",
    "gcs_bucket_name = \"trading_data_new\"  # Replace with your GCS bucket name\n",
    "# Specify the path to the service account key file\n",
    "key_path = \"/Users/Rohaan/Desktop/DE/Data_Engineering_Project/key.json\"\n",
    "# Create credentials\n",
    "credentials = service_account.Credentials.from_service_account_file(key_path)\n",
    "# Use credentials for authentication\n",
    "gcs_client = storage.Client(credentials=credentials)\n",
    "\n",
    "\n",
    "# Set GCP credentials environment variable\n",
    "# os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/Users/Rohaan/Desktop/DE/Data_Engineering_Project/key.json\"\n",
    "\n",
    "# Kafka configuration\n",
    "kafka_bootstrap_servers = \"localhost:9092\"\n",
    "kafka_topic = \"Topic_1_Trade_Data\"\n",
    "\n",
    "# Create Kafka producer\n",
    "kafka_producer = KafkaProducer(\n",
    "    bootstrap_servers=kafka_bootstrap_servers,\n",
    "    api_version=(0, 11, 5),\n",
    "    value_serializer=lambda v: json.dumps(v, default=str).encode('utf-8')\n",
    ")\n",
    "\n",
    "# Main loop to continuously update the database and upload to GCS\n",
    "while True:\n",
    "    # Fetch data using yfinance\n",
    "    ticker = \"UBER\"  # Replace with your desired ticker symbol\n",
    "    data = yf.download(ticker, period=\"1d\", interval=\"1m\")\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Generate a unique name for the DataFrame\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    df_name = f\"data_{timestamp}\"\n",
    "\n",
    "    # Send data to Kafka topic\n",
    "    kafka_producer.send(kafka_topic, value=df_name.encode('utf-8'))\n",
    "\n",
    "    # Insert data into MongoDB\n",
    "    collection.insert_many(df.to_dict(orient=\"records\"))\n",
    "\n",
    "    # Upload data to GCS\n",
    "    bucket = gcs_client.bucket(gcs_bucket_name)\n",
    "    blob = bucket.blob(f\"{df_name}.csv\")\n",
    "    blob.upload_from_string(df.to_csv(index=False), content_type=\"text/csv\")\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "print(\"Execution stopped by user\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb Cell 8\u001b[0m in \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb#X10sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb#X10sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     \u001b[39m# Fetch data using yfinance\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb#X10sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     ticker \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mUBER\u001b[39m\u001b[39m\"\u001b[39m  \u001b[39m# Replace with your desired ticker symbol\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb#X10sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     data \u001b[39m=\u001b[39m yf\u001b[39m.\u001b[39;49mdownload(ticker, period\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m1d\u001b[39;49m\u001b[39m\"\u001b[39;49m, interval\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m1m\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb#X10sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(data)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb#X10sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     \u001b[39m# Add the dataframe to the list\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SRH_Python/lib/python3.9/site-packages/yfinance/multi.py:144\u001b[0m, in \u001b[0;36mdownload\u001b[0;34m(tickers, start, end, actions, threads, ignore_tz, group_by, auto_adjust, back_adjust, repair, keepna, progress, period, show_errors, interval, prepost, proxy, rounding, timeout, session)\u001b[0m\n\u001b[1;32m    137\u001b[0m         _download_one_threaded(ticker, period\u001b[39m=\u001b[39mperiod, interval\u001b[39m=\u001b[39minterval,\n\u001b[1;32m    138\u001b[0m                                start\u001b[39m=\u001b[39mstart, end\u001b[39m=\u001b[39mend, prepost\u001b[39m=\u001b[39mprepost,\n\u001b[1;32m    139\u001b[0m                                actions\u001b[39m=\u001b[39mactions, auto_adjust\u001b[39m=\u001b[39mauto_adjust,\n\u001b[1;32m    140\u001b[0m                                back_adjust\u001b[39m=\u001b[39mback_adjust, repair\u001b[39m=\u001b[39mrepair, keepna\u001b[39m=\u001b[39mkeepna,\n\u001b[1;32m    141\u001b[0m                                progress\u001b[39m=\u001b[39m(progress \u001b[39mand\u001b[39;00m i \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m), proxy\u001b[39m=\u001b[39mproxy,\n\u001b[1;32m    142\u001b[0m                                rounding\u001b[39m=\u001b[39mrounding, timeout\u001b[39m=\u001b[39mtimeout, session\u001b[39m=\u001b[39msession)\n\u001b[1;32m    143\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mlen\u001b[39m(shared\u001b[39m.\u001b[39m_DFS) \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(tickers):\n\u001b[0;32m--> 144\u001b[0m         _time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n\u001b[1;32m    145\u001b[0m \u001b[39m# download synchronously\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    147\u001b[0m     \u001b[39mfor\u001b[39;00m i, ticker \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tickers):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from google.cloud import storage\n",
    "import os\n",
    "import time\n",
    "from kafka import KafkaProducer\n",
    "import json\n",
    "from datetime import datetime\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient(\"mongodb://localhost:27017\")\n",
    "db = client[\"DE_new\"]\n",
    "collection = db[\"col_1\"]\n",
    "\n",
    "# GCS configuration\n",
    "gcs_bucket_name = \"trading_data_new\"  # Replace with your GCS bucket name\n",
    "# Specify the path to the service account key file\n",
    "key_path = \"/Users/Rohaan/Desktop/DE/Data_Engineering_Project/key.json\"\n",
    "# Create credentials\n",
    "credentials = service_account.Credentials.from_service_account_file(key_path)\n",
    "# Use credentials for authentication\n",
    "gcs_client = storage.Client(credentials=credentials)\n",
    "\n",
    "\n",
    "# Set GCP credentials environment variable\n",
    "# os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/Users/Rohaan/Desktop/DE/Data_Engineering_Project/key.json\"\n",
    "\n",
    "# Kafka configuration\n",
    "kafka_bootstrap_servers = \"localhost:9092\"\n",
    "kafka_topic = \"Topic_1_Trade_Data\"\n",
    "\n",
    "# Create Kafka producer\n",
    "kafka_producer = KafkaProducer(\n",
    "    bootstrap_servers=kafka_bootstrap_servers,\n",
    "    api_version=(0, 11, 5),\n",
    "    value_serializer=lambda v: json.dumps(v, default=str).encode('utf-8')\n",
    ")\n",
    "\n",
    "# Initialize an empty list to store dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Main loop to continuously update the database and upload to GCS\n",
    "while True:\n",
    "    # Fetch data using yfinance\n",
    "    ticker = \"UBER\"  # Replace with your desired ticker symbol\n",
    "    data = yf.download(ticker, period=\"1d\", interval=\"1m\")\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Add the dataframe to the list\n",
    "    dataframes.append(df)\n",
    "\n",
    "    # Send data to Kafka topic\n",
    "    kafka_producer.send(kafka_topic, value=\"Data received\".encode('utf-8'))\n",
    "\n",
    "    # Insert data into MongoDB\n",
    "    collection.insert_many(df.to_dict(orient=\"records\"))\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "    # Check if the loop has iterated for the desired number of times\n",
    "    if len(dataframes) == 4:\n",
    "        # Concatenate all dataframes into a single dataframe\n",
    "        combined_df = pd.concat(dataframes)\n",
    "\n",
    "        # Generate a unique name for the combined dataframe\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        combined_df_name = f\"data_{timestamp}\"\n",
    "\n",
    "        # Upload the combined dataframe to GCS\n",
    "        bucket = gcs_client.bucket(gcs_bucket_name)\n",
    "        blob = bucket.blob(f\"{combined_df_name}.csv\")\n",
    "        blob.upload_from_string(combined_df.to_csv(index=False), content_type=\"text/csv\")\n",
    "\n",
    "        # Clear the list of dataframes for the next iteration\n",
    "        dataframes = []\n",
    "\n",
    "print(\"Execution stopped by user\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb Cell 9\u001b[0m in \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb#X11sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m     blob \u001b[39m=\u001b[39m bucket\u001b[39m.\u001b[39mblob(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdata_\u001b[39m\u001b[39m{\u001b[39;00mtimestamp\u001b[39m}\u001b[39;00m\u001b[39m.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb#X11sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m     blob\u001b[39m.\u001b[39mupload_from_string(df\u001b[39m.\u001b[39mto_csv(index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m), content_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtext/csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb#X11sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m2\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb#X11sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mExecution stopped by user\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from google.cloud import storage\n",
    "import os\n",
    "import time\n",
    "from kafka import KafkaProducer\n",
    "import json\n",
    "from datetime import datetime\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient(\"mongodb://localhost:27017\")\n",
    "db = client[\"DE_new\"]\n",
    "\n",
    "# GCS configuration\n",
    "gcs_bucket_name = \"trading_data_new\"  # Replace with your GCS bucket name\n",
    "# Specify the path to the service account key file\n",
    "key_path = \"/Users/Rohaan/Desktop/DE/Data_Engineering_Project/key.json\"\n",
    "# Create credentials\n",
    "credentials = service_account.Credentials.from_service_account_file(key_path)\n",
    "# Use credentials for authentication\n",
    "gcs_client = storage.Client(credentials=credentials)\n",
    "\n",
    "\n",
    "# Set GCP credentials environment variable\n",
    "# os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/Users/Rohaan/Desktop/DE/Data_Engineering_Project/key.json\"\n",
    "\n",
    "# Kafka configuration\n",
    "kafka_bootstrap_servers = \"localhost:9092\"\n",
    "kafka_topic = \"Topic_1_Trade_Data\"\n",
    "\n",
    "# Create Kafka producer\n",
    "kafka_producer = KafkaProducer(\n",
    "    bootstrap_servers=kafka_bootstrap_servers,\n",
    "    api_version=(0, 11, 5),\n",
    "    value_serializer=lambda v: json.dumps(v, default=str).encode('utf-8')\n",
    ")\n",
    "\n",
    "# Main loop to continuously update the database and upload to GCS\n",
    "while True:\n",
    "    # Delete existing collections\n",
    "    existing_collections = db.list_collection_names()\n",
    "    for collection_name in existing_collections:\n",
    "        db[collection_name].drop()\n",
    "\n",
    "    # Generate a unique name for the new collection\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    collection_name = f\"col_{timestamp}\"\n",
    "\n",
    "    # Create a new collection\n",
    "    collection = db[collection_name]\n",
    "\n",
    "    # Fetch data using yfinance\n",
    "    ticker = \"UBER\"  # Replace with your desired ticker symbol\n",
    "    data = yf.download(ticker, period=\"1d\", interval=\"1m\")\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Send data to Kafka topic\n",
    "    kafka_producer.send(kafka_topic, value=\"Data received\".encode('utf-8'))\n",
    "\n",
    "    # Insert data into MongoDB\n",
    "    collection.insert_many(df.to_dict(orient=\"records\"))\n",
    "\n",
    "    # Upload data to GCS\n",
    "    bucket = gcs_client.bucket(gcs_bucket_name)\n",
    "    blob = bucket.blob(f\"data_{timestamp}.csv\")\n",
    "    blob.upload_from_string(df.to_csv(index=False), content_type=\"text/csv\")\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "print(\"Execution stopped by user\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb Cell 10\u001b[0m in \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb#X12sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m     blob \u001b[39m=\u001b[39m bucket\u001b[39m.\u001b[39mblob(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdata_\u001b[39m\u001b[39m{\u001b[39;00mtimestamp\u001b[39m}\u001b[39;00m\u001b[39m.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb#X12sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m     blob\u001b[39m.\u001b[39mupload_from_string(combined_df\u001b[39m.\u001b[39mto_csv(index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m), content_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtext/csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb#X12sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m2\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb#X12sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mExecution stopped by user\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#final working code \n",
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from google.cloud import storage\n",
    "import os\n",
    "import time\n",
    "from kafka import KafkaProducer\n",
    "import json\n",
    "from datetime import datetime\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient(\"mongodb://localhost:27017\")\n",
    "db = client[\"DE_new\"]\n",
    "\n",
    "# GCS configuration\n",
    "gcs_bucket_name = \"trading_data_new\"  # Replace with your GCS bucket name\n",
    "# Specify the path to the service account key file\n",
    "key_path = \"/Users/Rohaan/Desktop/DE/Data_Engineering_Project/key.json\"\n",
    "# Create credentials\n",
    "credentials = service_account.Credentials.from_service_account_file(key_path)\n",
    "# Use credentials for authentication\n",
    "gcs_client = storage.Client(credentials=credentials)\n",
    "\n",
    "\n",
    "# Set GCP credentials environment variable\n",
    "# os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/Users/Rohaan/Desktop/DE/Data_Engineering_Project/key.json\"\n",
    "\n",
    "# Kafka configuration\n",
    "kafka_bootstrap_servers = \"localhost:9092\"\n",
    "kafka_topic = \"Topic_1_Trade_Data\"\n",
    "\n",
    "# Create Kafka producer\n",
    "kafka_producer = KafkaProducer(\n",
    "    bootstrap_servers=kafka_bootstrap_servers,\n",
    "    api_version=(0, 11, 5),\n",
    "    value_serializer=lambda v: json.dumps(v, default=str).encode('utf-8')\n",
    ")\n",
    "\n",
    "# Dataframes list\n",
    "dataframes = []\n",
    "\n",
    "# Main loop to continuously update the database and upload to GCS\n",
    "while True:\n",
    "    # Delete existing collections\n",
    "    existing_collections = db.list_collection_names()\n",
    "    for collection_name in existing_collections:\n",
    "        db[collection_name].drop()\n",
    "\n",
    "    # Generate a unique name for the new collection\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    collection_name = f\"col_{timestamp}\"\n",
    "\n",
    "    # Create a new collection\n",
    "    collection = db[collection_name]\n",
    "\n",
    "    # Fetch data using yfinance\n",
    "    ticker = \"UBER\"  # Replace with your desired ticker symbol\n",
    "    data = yf.download(ticker, period=\"1d\", interval=\"1m\")\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Append dataframe to the list\n",
    "    dataframes.append(df)\n",
    "\n",
    "    # Combine all dataframes\n",
    "    combined_df = pd.concat(dataframes)\n",
    "\n",
    "    # Send data to Kafka topic\n",
    "    kafka_producer.send(kafka_topic, value=\"Data received\".encode('utf-8'))\n",
    "\n",
    "    # Insert data into MongoDB\n",
    "    collection.insert_many(df.to_dict(orient=\"records\"))\n",
    "\n",
    "    # Upload data to GCS\n",
    "    bucket = gcs_client.bucket(gcs_bucket_name)\n",
    "    blob = bucket.blob(f\"data_{timestamp}.csv\")\n",
    "    blob.upload_from_string(combined_df.to_csv(index=False), content_type=\"text/csv\")\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "print(\"Execution stopped by user\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb Cell 11\u001b[0m in \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb#X13sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m     \u001b[39m# Send data to Kafka topic\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb#X13sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m     kafka_producer\u001b[39m.\u001b[39msend(kafka_topic, value\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mData received\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mencode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb#X13sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m2\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Rohaan/Desktop/DE/Data_Engineering_Project/new.ipynb#X13sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mExecution stopped by user\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from google.cloud import storage\n",
    "import os\n",
    "import time\n",
    "from kafka import KafkaProducer\n",
    "import json\n",
    "from datetime import datetime, date\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient(\"mongodb://localhost:27017\")\n",
    "db = client[\"DE_new\"]\n",
    "\n",
    "# GCS configuration\n",
    "gcs_bucket_name = \"trading_data_new\"  # Replace with your GCS bucket name\n",
    "# Specify the path to the service account key file\n",
    "key_path = \"/Users/Rohaan/Desktop/DE/Data_Engineering_Project/key.json\"\n",
    "# Create credentials\n",
    "credentials = service_account.Credentials.from_service_account_file(key_path)\n",
    "# Use credentials for authentication\n",
    "gcs_client = storage.Client(credentials=credentials)\n",
    "\n",
    "\n",
    "# Set GCP credentials environment variable\n",
    "# os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/Users/Rohaan/Desktop/DE/Data_Engineering_Project/key.json\"\n",
    "\n",
    "# Kafka configuration\n",
    "kafka_bootstrap_servers = \"localhost:9092\"\n",
    "kafka_topic = \"Topic_1_Trade_Data\"\n",
    "\n",
    "# Create Kafka producer\n",
    "kafka_producer = KafkaProducer(\n",
    "    bootstrap_servers=kafka_bootstrap_servers,\n",
    "    api_version=(0, 11, 5),\n",
    "    value_serializer=lambda v: json.dumps(v, default=str).encode('utf-8')\n",
    ")\n",
    "\n",
    "# Main loop to continuously update the database and upload to GCP\n",
    "while True:\n",
    "    # Delete existing collections in MongoDB\n",
    "    existing_collections = db.list_collection_names()\n",
    "    for collection_name in existing_collections:\n",
    "        db[collection_name].drop()\n",
    "\n",
    "    # Generate a unique name for the new collection in MongoDB\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    collection_name = f\"col_{timestamp}\"\n",
    "    collection = db[collection_name]\n",
    "\n",
    "    # Fetch data using yfinance\n",
    "    ticker = \"UBER\"  # Replace with your desired ticker symbol\n",
    "    data = yf.download(ticker, period=\"1d\", interval=\"1m\")\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Upload data to MongoDB\n",
    "    collection.insert_many(df.to_dict(orient=\"records\"))\n",
    "\n",
    "    # Generate a unique name for the file in GCS\n",
    "    gcp_timestamp = date.today().strftime(\"%Y%m%d\")\n",
    "    gcp_file_name = f\"data_{gcp_timestamp}.csv\"\n",
    "\n",
    "    # Upload data to GCP and delete existing data for the current day\n",
    "    bucket = gcs_client.bucket(gcs_bucket_name)\n",
    "    blob = bucket.blob(gcp_file_name)\n",
    "\n",
    "    if blob.exists():\n",
    "        # Delete existing data for the current day\n",
    "        blob.delete()\n",
    "\n",
    "    # Upload the new data to GCP\n",
    "    blob.upload_from_string(df.to_csv(index=False), content_type=\"text/csv\")\n",
    "\n",
    "    # Send data to Kafka topic\n",
    "    kafka_producer.send(kafka_topic, value=\"Data received\".encode('utf-8'))\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "print(\"Execution stopped by user\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Rohaan/Desktop/DE/Data_Engineering_Project'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SRH_Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
